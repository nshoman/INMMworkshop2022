{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9621fc42-c8ee-4be2-a029-87824628ec3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# UF6 Container Identification Hackathon\n",
    "\n",
    "Scott Stewart  \n",
    "Nathan Shoman  \n",
    "Mark Adams  \n",
    "Nathan Martindale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3c801-4f2c-42c0-bfaa-7dc8f1863f77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Session Objective & General Information\n",
    "2. Registration\n",
    "3. General Information\n",
    "4. Evaluation Criteria\n",
    "5. Submission Format\n",
    "6. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4f7d4-702c-4d7a-9132-58787a6c0dc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Session Objective\n",
    "\n",
    "We would like participants in the session today to go from a starter Jupyter notebook to making a preliminary submission to the competition. \n",
    "\n",
    "We will be keeping the competition open through Saturday, July 30.\n",
    "\n",
    "## Schedule\n",
    "\n",
    "- 9:00 AM - 9:15 AM - Introduction\n",
    "- 9:15 AM - 10:00 AM - Work Solutions Individually\n",
    "- 10:00 AM - 10:30 AM - Demonstration of a Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71df53-f96a-4164-bdb7-0fa395208e47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## General Information\n",
    "\n",
    "Please go find out helper material here (including these slides so you can click links): https://github.com/nshoman/INMMworkshop2022\n",
    "\n",
    "This competition is based on the [Limbo dataset](https://limbo-ml.readthedocs.io/en/latest/index.html) which is discussed in a publication by [Gastelum, et al.](https://esarda.jrc.ec.europa.eu/esarda-43rd-joint-annual-meeting_en) in the ESARDA 43rd Joint Annual Meeting proceedings. \n",
    "\n",
    "From the documentation: \n",
    "\n",
    "> Limbo Data is a growing collection (400000 images and counting) of synthetic computer vision training data that we created for our research. The subject matter of the dataset is uranium hexaflouride containers that are part of the nuclear fuel cycle. \n",
    "\n",
    "Your task is to develop a machine learning algorithm that can detect whether an image contains a uranium hexaflouride container. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e9cec-baf5-431e-89ac-30b067466f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T20:42:17.491846Z",
     "iopub.status.busy": "2022-07-25T20:42:17.491051Z",
     "iopub.status.idle": "2022-07-25T20:42:17.512782Z",
     "shell.execute_reply": "2022-07-25T20:42:17.511059Z",
     "shell.execute_reply.started": "2022-07-25T20:42:17.491708Z"
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Registration\n",
    "\n",
    "- Please let us know who you are before submission by registering using our [Google form](https://forms.gle/NkDwUKFWRUK6C5g66). \n",
    "- Once you use the Google form use this [Kaggle link](https://www.kaggle.com/t/1c59ed8b0ef14762a6ea3fb476f8c97b) to access the competition\n",
    "- We encourage you to join our [Discord server](https://discord.gg/C4w9hyuJ29) to learn more about the INMM data science working group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fee5f-c058-430b-9644-cca5e1241120",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Evaluation Criteria\n",
    "\n",
    "Your trained machine learning algorithm will be evaluated by the [Mean F1-Score](https://en.wikipedia.org/wiki/F-score) on predictions for the test dataset. Kaggle does not directly evaluate your trained model and instead evaluates your predictions against a solution file. To keep the competition fair for all, do not manually label and/or train on the test dataset.\n",
    "\n",
    "Submissions will be evaluated against a smaller, randomized subset of the test dataset (roughly 30%), which will inform the leader board score. The majority of the data (roughly 70%) will be withheld to perform the final evaluation to determine standings at the end of the competition. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ef014-b357-44c2-aea5-1da4c1479b70",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Mean F1-Score Information\n",
    "\n",
    "The F1 score, commonly used in information retrieval, measures accuracy using the statistics precision $\\text{p}$ and recall $\\text{r}$. \n",
    "\n",
    "Precision is the ratio of true positives $\\text{tp}$ to all predicted positives $\\text{tp} + \\text{fp}$. Recall is the ratio of true positives $\\text{tp}$ to all actual positives $\\text{tp} + \\text{fn}$. The F1 score is given by:\n",
    "\n",
    "$$\\text{F1} = 2\\frac{\\text{p} \\cdot \\text{r}}{\\text{p}+\\text{r}}\\ \\ \\mathrm{where}\\ \\ \\text{p} = \\frac{\\text{tp}}{\\text{tp}+\\text{fp}},\\ \\ \\text{r} = \\frac{\\text{tp}}{\\text{tp}+\\text{fn}}$$\n",
    "\n",
    "The F1 metric weights recall and precision equally, and a good retrieval algorithm will maximize both precision and recall simultaneously. Thus, moderately good performance on both will be favored over extremely good performance on one and poor performance on the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f9ddf7-decd-4d34-bfb6-bc8c3c1557dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Submission Format\n",
    "\n",
    "The submission file, generated from your trained model evaluated on the test dataset, should contain two columns: `Label` and `ImageID`. The `Label` column should either be a value of 0 (indicating no cylinder present) or a value of 1 (indicating a cylinder is present). The `ImageID` should correspond to a file in the test dataset. Note that the solution file expects the file extension attached to the file name (e.g. `.png` in `Image001.png` is required).\n",
    "\n",
    "\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "| Label       | ImageID |\n",
    "| ----------- | ----------- |\n",
    "| 0      | Image994.png       |\n",
    "| 1      | Image082.png       |\n",
    "| ...      | ...      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a917305-ba01-4537-9d8b-f293d1dbcb4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Getting Started with Machine Learning on Kaggle\n",
    "\n",
    "Kaggle has online code notebooks with preconfigured development environments that you can use for creating your solution. To use this feature, navigate to the UF6 Container Identification competition: [https://www.kaggle.com/competitions/containerid](https://www.kaggle.com/competitions/containerid). Go to the [\"Code\" tab](https://www.kaggle.com/competitions/containerid/code) and then hit \"New Notebook\". All your code can be written and submitted through this interface. See the \"Evaluation\" section of the overview page to see the expected submission file format. Submission files can be generated and output from within your notebook, look [here for an example](https://www.kaggle.com/code/dansbecker/submitting-from-a-kernel/notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86760ef9-8c52-42a6-b673-923d3a7dc04e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img width=\"750\" src='screenshot_code_notebook.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782ccf2c-8e80-4d82-99af-9f57f5e63d2d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Download the repository at [https://github.com/nshoman/INMMworkshop2022](https://github.com/nshoman/INMMworkshop2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c8f924-f8e5-4e21-b966-4ec2cb4079d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "To get the starter data loading code into your kaggle notebook, click on \"File\", \"Import Notebook\", and select the `base.ipynb` file from the downloaded repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7746dca8-2783-4f8e-beac-9b700623389a",
   "metadata": {},
   "source": [
    "<img src='screenshot_notebook.png' width='1000px'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792ef91-640b-464b-8f41-68c3fdb83e7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Within the kaggle notebook, all data is available at the `/kaggle/input/containerid` path, and you can access the table with labels with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05018c4b-daf2-438b-95df-cc953985f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annotations_df = pd.read_csv(\"/kaggle/input/containerid/train_annotations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481671dc-72c1-4318-972c-2d295cea6094",
   "metadata": {},
   "source": [
    "All of the training images can be found in the `/kaggle/input/containerid/train/train` directory. The test images, for which you need to generate the table containing the predicted labels, are in the `/kaggle/input/containerid/test/test` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc56acc-7afa-4ad4-a775-6d9455363bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Kaggle includes learning resources to help you get started. If you click on the \"courses\" in the left sidebar you will find several tutorials and exercises for various python, data science, and machine learning topics. The computer vision one may be especially relevant and can be found [here](https://www.kaggle.com/learn/computer-vision). This example walks you through the basics of making and customizing convolutional neural networks with keras/tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9181c8-e97f-4b51-8f15-4472b6697a9a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<img src='screenshot_courses.png' width='800px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3fc967-0029-48b1-9bdb-df2317eec64e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Some Additional Resources\n",
    "\n",
    "Massive Tutorial on Image Processing and Preparation for Deep Learning in Python:\n",
    "\n",
    "- [Part 1](https://towardsdatascience.com/massive-tutorial-on-image-processing-and-preparation-for-deep-learning-in-python-1-e534ee42f122)\n",
    "- [Part 2](https://towardsdatascience.com/massive-tutorial-on-image-processing-and-preparation-for-deep-learning-in-python-2-14816263b4a5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "947a3de5-be23-4028-a7db-c02446548213",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "<style>\n",
    ":root {\n",
    "    --primary: #23FF89;\n",
    "}\n",
    "\n",
    "body {\n",
    "    background-color: #111914 !important;\n",
    "}\n",
    "\n",
    ".reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5 {\n",
    "    color: var(--primary) !important;\n",
    "    font-family: Impact;\n",
    "}\n",
    ".reveal p, .reveal li {\n",
    "    color: white !important;\n",
    "}\n",
    ".reveal .controls button {\n",
    "    color: var(--primary);\n",
    "}\n",
    ".reveal a {\n",
    "    color: var(--primary) !important;\n",
    "    text-decoration: underline !important;\n",
    "}\n",
    ".reveal .progress span {\n",
    "    background: var(--primary) !important;\n",
    "}\n",
    ".reveal blockquote {\n",
    "    padding-left: 20px;\n",
    "    padding-right: 20px;\n",
    "}\n",
    "\n",
    ".reveal .slides {\n",
    "    width: 1200px !important;\n",
    "}\n",
    "\n",
    ".reveal table thead {\n",
    "    color: white;\n",
    "    background: #222622;\n",
    "}\n",
    ".reveal table tbody tr:nth-child(odd) {\n",
    "    background: #333733 !important;\n",
    "    color: white;\n",
    "}\n",
    ".reveal table tbody tr:nth-child(even) {\n",
    "    background: #444844 !important;\n",
    "    color: white\n",
    "}\n",
    "\n",
    "/* this if you only want to color the multiline math mode stuff */\n",
    "/*.mjx-math { \n",
    "    color: white !important;\n",
    "}*/\n",
    "/* this to color all math */\n",
    ".mjx-chtml {\n",
    "    color: silver !important;\n",
    "}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
